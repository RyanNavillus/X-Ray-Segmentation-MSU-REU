{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../segmentation_models\")\n",
    "sys.path.insert(0,\"../classification_models\")\n",
    "\n",
    "import collections\n",
    "import cv2 \n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import classification_models\n",
    "import segmentation_models\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy import io\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models.utils import set_trainable\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (512,512)\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"Load grayscale image from path\"\"\"\n",
    "    return cv2.resize(cv2.imread(path,1), input_size)\n",
    "\n",
    "def load_binary_image(path):\n",
    "    \"\"\"Load grayscale image from path\"\"\"\n",
    "    return cv2.resize(cv2.imread(path,0), input_size)\n",
    "\n",
    "def load_mat(path):\n",
    "    \"\"\"Load grayscale image from path\"\"\"\n",
    "    image = io.loadmat(path, appendmat=False)['dxImage']['img'][0][0]\n",
    "    normalized_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    colored_image = cv2.cvtColor(normalized_image, cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(colored_image, input_size)\n",
    "\n",
    "def load_mask_mat(path):\n",
    "    \"\"\"Load grayscale image from path\"\"\"\n",
    "    # import matlab files, extracting array of masks\n",
    "    mask_list = np.stack(io.loadmat(path, appendmat=False)['maskImage']['maskCrop'][0][0][0], axis=0)\n",
    "    line_num = len(mask_list)\n",
    "    \n",
    "    # create placeholder arrays\n",
    "    foreground = np.zeros((input_size[0], input_size[1], 1))\n",
    "    background = np.ones((input_size[0], input_size[1], 1))\n",
    "    \n",
    "    # for each mask, scale it, reshape it, and add it to the foreground\n",
    "    for i, mask in enumerate(mask_list):\n",
    "        mask_array = cv2.resize(mask.astype(np.uint8), input_size)\n",
    "        scaled_mask_array = np.reshape(mask_array, (input_size[0], input_size[1], 1))\n",
    "        foreground = np.logical_or(foreground, scaled_mask_array)\n",
    "    foreground = np.reshape(foreground, (1, input_size[0], input_size[1], 1))\n",
    "    \n",
    "    # create the background mask\n",
    "    background = 1 - foreground\n",
    "    \n",
    "    # combine the background and foreground masks into a single array\n",
    "    final_mask_list = np.array(np.append(background, foreground, axis=3))\n",
    "    return final_mask_list\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "data_dir = \"/data/midi-lab-general/osemis_annotations/osemis_annotation_file_to_masks/Masks/*.mat\"\n",
    "for filepath in tqdm(sorted(glob.glob(data_dir, recursive=True))):\n",
    "    if filepath.endswith(\"image.mat\"):\n",
    "        X.append(load_mat(filepath))\n",
    "    if filepath.endswith(\"mask.mat\"):\n",
    "        Y.append(load_mask_mat(filepath))\n",
    "X = np.reshape(np.array(X), (-1, input_size[0], input_size[1], 3))\n",
    "Y = np.reshape(np.array(Y), (len(X), input_size[0], input_size[1], 2))\n",
    "\n",
    "line_ratio = 0\n",
    "for image in Y[:,:,:,0]:\n",
    "    image = np.round(image, decimals=0)\n",
    "    unique, counts = np.unique(image, return_counts=True)\n",
    "    d = dict(zip(unique, counts))\n",
    "    line_ratio += d[1.0]/(d[1.0] + d[0.0])\n",
    "print(line_ratio/len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.15\n",
    "test_split = 0.15\n",
    "n = len(X)\n",
    "sp1 = int(((1 - val_split - test_split) * n) - 0.5) # Choose first index with rounding adjustment (0.5)\n",
    "sp2 = int(((1 - test_split) * n) - 0.5) # Choose second index with rounding adjustment (0.5)\n",
    "X_train, Y_train = X[:sp1], Y[:sp1]\n",
    "X_val, Y_val = X[sp1:sp2], Y[sp1:sp2]\n",
    "X_test, Y_test = X[sp2:], Y[sp2:]\n",
    "X_train = X_train[:15]\n",
    "Y_train = Y_train[:15]\n",
    "print(\"{} Samples; {} train; {} val; {} test\".format(n, len(X_train), len(X_val), len(X_test)))\n",
    "def plot_sample(sample, figsize=(10,10)):\n",
    "    print(sample.shape)\n",
    "    sample = np.squeeze(sample)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(sample, cmap='gray')\n",
    "    plt.show()\n",
    "def plot_mask(sample, mask, figsize=(10,10)):\n",
    "    mask = np.squeeze(mask)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(sample, cmap='gray')\n",
    "    plt.imshow(np.ma.masked_where(mask[:, :, 1] <= 0.5, mask[:, :, 1]), cmap='jet', alpha=0.5, vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "plot_mask(X[2], Y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.0001\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = y_true[:, :, :, 1]\n",
    "    y_pred = y_pred[:, :, :, 1]\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + epsilon) / (K.sum(y_true_f) + K.sum(y_pred_f) + epsilon)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def weighted_cce(y_true, y_pred):\n",
    "    p = K.sum(K.flatten(y_true[...,:1])) / (224**2)\n",
    "    maximum_w = 1 / K.log(1.02 + 0)\n",
    "    minimum_w = 1 / K.log(1.02 + 1)\n",
    "    w = 1 / K.log(1.02 + p)\n",
    "    scaled_w = (w - minimum_w) / (maximum_w - minimum_w)\n",
    "    \n",
    "    y_pred = K.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    loss_map = -K.sum(scaled_w * y_true * K.log(y_pred), axis=-1)\n",
    "    return K.mean(K.flatten(loss_map))\n",
    "\n",
    "def weighted_cce_plus_dice_coef_loss(y_true, y_pred):\n",
    "    return 0.5*weighted_cce(y_true, y_pred) + 0.5*dice_coef_loss(y_true, y_pred)\n",
    "\n",
    "def unbalanced_weighted_cce_plus_dice_coef_loss(y_true, y_pred):\n",
    "    return 0.1*weighted_cce(y_true, y_pred) + 0.9*dice_coef_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create UNet model with custom resnet weights\n",
    "model = Unet('resnet50_custom', \n",
    "             classes=2, \n",
    "             input_shape=(512, 512, 3), \n",
    "             encoder_weights='imagenet', \n",
    "             activation='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001), loss=dice_coef_loss, metrics=[\"accuracy\", dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose checkpoint path\n",
    "checkpoint_path = \"./UNET-with-New-ResNet50_weights\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "# Create early stopping callback\n",
    "early_stopping = EarlyStopping(monitor=\"val_dice_coef\", mode=\"max\", patience=75, verbose=1)\n",
    "\n",
    "# Create checkpointer to save best model weights\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_path + \"/resnet50-custom_small_dice_weights.h5\", verbose=1, monitor=\"val_dice_coef\", mode=\"max\", save_best_only=True)\n",
    "\n",
    "# TEST: ReduceLROnPlateau\n",
    "callback_list = [checkpointer, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=8, epochs=50, verbose=1, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "history_path = checkpoint_path + \"/History/\" + \"resnet50-custom_small_dice_history.json\"\n",
    "print(\"Writing history dictionary to {}\".format(history_path))\n",
    "with open(history_path, 'w') as history_file:\n",
    "    json.dump(res_history.history, history_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path + \"/resnet50-custom_small_dice_weights.h5\")\n",
    "loss, accuracy, dice = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "print('Dice coef:', dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "plt.plot(res_history.history['acc'])\n",
    "plt.plot(res_history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(res_history.history['loss'])\n",
    "plt.plot(res_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation dice values\n",
    "plt.plot(res_history.history['dice_coef'])\n",
    "plt.plot(res_history.history['val_dice_coef'])\n",
    "plt.title('Model dice coef')\n",
    "plt.ylabel('Dice coef')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1\n",
    "predicted_mask = model.predict(np.expand_dims(X_test[test_id], axis=0))\n",
    "plot_mask(X_test[test_id], predicted_mask, figsize=(10,10))\n",
    "plot_mask(X_test[test_id], Y_test[test_id], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del model # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tf.Session(config=config))\n",
    "reset_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNet model with imagenet weights\n",
    "model = Unet('resnet50', \n",
    "             classes=2, \n",
    "             input_shape=(512, 512, 3), \n",
    "             encoder_weights='imagenet', \n",
    "             activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose checkpoint path\n",
    "checkpoint_path = \"./UNET-with-New-ResNet50_weights\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "# Create early stopping callback\n",
    "early_stopping = EarlyStopping(monitor=\"val_dice_coef\", mode=\"max\", patience=100)\n",
    "\n",
    "# Create checkpointer to save best model weights\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_path + \"/resnet50_small_dice_weights.h5\", verbose=1, monitor=\"val_dice_coef\", mode=\"max\", save_best_only=True)\n",
    "\n",
    "# TEST: ReduceLROnPlateau\n",
    "callback_list = [checkpointer, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001), loss=dice_coef_loss, metrics=[\"accuracy\", dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imagenet_history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=8, epochs=50, verbose=1, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path + \"/resnet50_small_dice_weights.h5\")\n",
    "loss, accuracy, dice = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "print('Dice coef:', dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_history = json.load(open(history_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(imagenet_history.history['acc'])\n",
    "plt.plot(imagenet_history.history['val_acc'])\n",
    "plt.plot(custom_history['acc'])\n",
    "plt.plot(custom_history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ImageNet Train', 'ImageNet Val', 'Custom Train', 'Custom Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(imagenet_history.history['loss'])\n",
    "plt.plot(imagenet_history.history['val_loss'])\n",
    "plt.plot(custom_history['loss'])\n",
    "plt.plot(custom_history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ImageNet Train', 'ImageNet Val', 'Custom Train', 'Custom Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation dice values\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(imagenet_history.history['dice_coef'])\n",
    "plt.plot(imagenet_history.history['val_dice_coef'])\n",
    "plt.plot(custom_history['dice_coef'])\n",
    "plt.plot(custom_history['val_dice_coef'])\n",
    "plt.title('Model dice coef')\n",
    "plt.ylabel('Dice coef')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['ImageNet Train', 'ImageNet Val', 'Custom Train', 'Custom Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_id = 1\n",
    "predicted_mask = model.predict(np.expand_dims(X_test[test_id], axis=0))\n",
    "plot_mask(X_test[test_id], predicted_mask)\n",
    "plot_mask(X_test[test_id], Y_test[test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
